## Implementing transformer from scratch

### The following have been implemented:
 - Self attention
 - Causal attention
 - Multi head attention

 ### TO DO
 - Train a small model on a dataset
 - Properly organize and refactor code 
 - Vectorize operations and remove redundancies/slow code
 - Add GPU acceleration support